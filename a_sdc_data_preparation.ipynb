{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finance V: Research Topics in Finance, Risk- and Resource management \n",
    "## Replication of paper: Lowry, Michaely & Volkova (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "    Author: Stefan Reimer <br>\n",
    "    Date: 2019-12-28 <br>\n",
    "    python version: 3.7 <br>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import packages and set general options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% import needed packages\n"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import re\n",
    "import collections\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# import defined functions\n",
    "from src.functions.functions import (data_import_chunkwise, min_max_print, convert_NAs, \n",
    "                                     get_duplicates, find_char_in_colnames, convert_date, \n",
    "                                     convert_price)\n",
    "\n",
    "# set the settings for displayed dataFrames\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load sdc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:loading started...\n",
      "INFO:root:loading finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loaded data frame has 43709 rows and 94 columns.\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# define path to files & load data chunkwise\n",
    "\n",
    "initialFolderPath = \"data/initial_data/\"\n",
    "cleanedFolderPath = \"data/cleaned_data/\"\n",
    "\n",
    "filePath = initialFolderPath + \"000_sdc_full.csv\"\n",
    "\n",
    "sdc_data = data_import_chunkwise(filePath=filePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of neede sample (from paper): 43816\n",
      "length of given sample: 43709\n",
      "difference of sample size: 107\n",
      "[IssueDate] min: 1973-01-02, max: 2019-12-13\n"
     ]
    }
   ],
   "source": [
    "# show first 5 rows\n",
    "#print(sdc_data.head(5))\n",
    "\n",
    "# show last 5 rows\n",
    "#print(sdc_data.tail(5))\n",
    "\n",
    "# get key statistics for data\n",
    "#print(sdc_data.describe())\n",
    "\n",
    "# show all columns names\n",
    "#print(sdc_data.columns)\n",
    "\n",
    "# inspect the sample size\n",
    "len_paper = 43816\n",
    "len_sample = len(sdc_data)\n",
    "\n",
    "print(f'length of neede sample (from paper): {len_paper}\\n'\n",
    "      f'length of given sample: {len_sample}\\n'\n",
    "     f'difference of sample size: {len_paper-len_sample}')\n",
    "\n",
    "# inspect the date range\n",
    "min_max_print(sdc_data, 'IssueDate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### +++ Comment +++\n",
    "the given SDC data sample is not exactly the same as in the inspected paper. \n",
    "One reason could be the extraction process of the countries\n",
    "Lowry et al. picked by excluding, not by including the choosen countries\n",
    "\n",
    "data horizont is enough, data is needed from 01.01.1973 until 31.12.2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDC data preparation\n",
    "\n",
    "- Sort dataFrame\n",
    "- choose only fulfilled IPOs\n",
    "- convert date information\n",
    "- convert price information\n",
    "- create year variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By including only IPOs, the data sample gets reduced from 43709 to 15247 samples.\n",
      "\n",
      " date range has been reduced to\n",
      "[IssueDate] min: 1973-01-02 00:00:00, max: 2016-12-27 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# sort dataFrame\n",
    "sdc_data = sdc_data.sort_index()\n",
    "\n",
    "# convert NAs in OrigIPO\n",
    "sdc_data = convert_NAs(sdc_data, 'OrigIPO', print_bool = False)\n",
    "\n",
    "# print values of IPO and OrigIPO\n",
    "# print(collections.Counter(sdc_data['OrigIPO']))\n",
    "# print(collections.Counter(sdc_data['IPO']))\n",
    "\n",
    "# keep only IPOs\n",
    "sdc_data = sdc_data.loc[(sdc_data['IPO']=='Yes') &\n",
    "                        (sdc_data['OrigIPO']!='No'), :]\n",
    "\n",
    "print(f'By including only IPOs, the data sample gets reduced from {len_sample} to {len(sdc_data)} samples.')\n",
    "\n",
    "# find all columns which contains some date information\n",
    "date_cols = find_char_in_colnames(sdc_data, 'Date', print_bool= False)\n",
    "\n",
    "# find all columns which contains some price information\n",
    "price_cols = find_char_in_colnames(sdc_data, 'Price', print_bool= False)\n",
    "\n",
    "# find all columns which contains some share information\n",
    "share_cols = find_char_in_colnames(sdc_data, 'Share', print_bool= False)\n",
    "\n",
    "# find all columns which contains some overallotment information\n",
    "overall_cols = find_char_in_colnames(sdc_data, 'Overall', print_bool= False)\n",
    "\n",
    "# find all columns which contains some round information\n",
    "round_cols = find_char_in_colnames(sdc_data, 'Round', print_bool= False)\n",
    "\n",
    "# convert and clean date columns\n",
    "for date_col in date_cols:\n",
    "    sdc_data = convert_date(sdc_data, date_col, format='%Y-%m-%d', errors='coerce', print_bool = False)\n",
    "\n",
    "# convert and clean price columns\n",
    "price_cols = np.setdiff1d(price_cols, ['HistoryHighFilingPrice', 'HistoryLowFilingPrice'])\n",
    "for price_col in price_cols:\n",
    "    sdc_data = convert_price(data = sdc_data, column = price_col, errors='coerce', print_bool = False)\n",
    "\n",
    "# convert proceeds column\n",
    "sdc_data = convert_price(sdc_data, 'ProceedsAmtInThisMktMil', print_bool= False)\n",
    "\n",
    "# create year variable\n",
    "sdc_data['Year'] = sdc_data['IssueDate'].dt.year\n",
    "\n",
    "# select date range\n",
    "sdc_data = sdc_data[(sdc_data['IssueDate'] > '1973-1-1') & (sdc_data['IssueDate'] <= '2016-12-31')]\n",
    "print('\\n date range has been reduced to') \n",
    "min_max_print(sdc_data, 'IssueDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 14524 rows. After: 10026 rows. \n",
      "4498 samples are dropped.\n"
     ]
    }
   ],
   "source": [
    "# clean the types of securites\n",
    "length_before = len(sdc_data)\n",
    "\n",
    "ex_types= [\"Units\", \"Ltd Prtnr Int\", \"MLP-Common Shs\", \"Shs Benficl Int\",\n",
    "             \"Ltd Liab Int\", \"Stock Unit\", \"Trust Units\", \"Beneficial Ints\"]\n",
    "sdc_data = sdc_data[~sdc_data.Type.isin(ex_types)]\n",
    "\n",
    "### drop REIT, Units, ADR, penny stocks and CEF ###\n",
    "\n",
    "# drop REIT - Real Estate Investment Trust\n",
    "sdc_data = sdc_data[sdc_data['REIT'].isna()]\n",
    "\n",
    "# drop Unit \n",
    "sdc_data = sdc_data[~(sdc_data['Unit'] == 'Yes')]\n",
    "\n",
    "# drop Depositary (ADR)\n",
    "sdc_data = sdc_data.loc[sdc_data['ADR']== 'No', :]\n",
    "\n",
    "# filter the offer prices (drop penny stocks)\n",
    "sdc_data[sdc_data['OfferPrice'].notna()]\n",
    "sdc_data = sdc_data[sdc_data['OfferPrice']>5]\n",
    "\n",
    "# filter CEF\n",
    "sdc_data = sdc_data[sdc_data['CEF'] == 'No']\n",
    "\n",
    "length_after = len(sdc_data)\n",
    "print(f'before: {length_before} rows. After: {length_after} rows. \\n'\n",
    "     f'{length_before - length_after} samples are dropped.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns containing <<CUSIP>> are:\n",
      "['CUSIP6' 'CUSIP9']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explore CUSIP\n",
    "cusip_cols = find_char_in_colnames(sdc_data, 'CUSIP')\n",
    "\n",
    "### creating 8-digit CUSIP to match with CRSP\n",
    "sdc_data['CUSIP8'] = sdc_data['CUSIP6'].astype(str) + '10'\n",
    "CUSIP9_sliced = sdc_data['CUSIP9'].str.slice(0, 8)\n",
    "sdc_data['CUSIP8'] = sdc_data['CUSIP8'].where(CUSIP9_sliced.isna(), CUSIP9_sliced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'00': 1,\n",
       "         '01': 1,\n",
       "         '10': 9592,\n",
       "         '11': 10,\n",
       "         '12': 1,\n",
       "         '13': 2,\n",
       "         '15': 2,\n",
       "         '20': 269,\n",
       "         '30': 84,\n",
       "         '40': 24,\n",
       "         '50': 19,\n",
       "         '60': 2,\n",
       "         '70': 3,\n",
       "         '80': 5,\n",
       "         '83': 1,\n",
       "         '85': 1,\n",
       "         '87': 3,\n",
       "         '88': 1,\n",
       "         '90': 1,\n",
       "         'AA': 2,\n",
       "         'B9': 1,\n",
       "         'HE': 1})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUSIP9_68 = sdc_data['CUSIP8'].str.slice(6, 8)\n",
    "collections.Counter(CUSIP9_68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned sdc_data has been saved.\n"
     ]
    }
   ],
   "source": [
    "# save cleaned sdc_data\n",
    "sdc_data.to_csv(cleanedFolderPath + \"sdc_data_cleaned.csv\", index=False)\n",
    "sdc_data.to_pickle(cleanedFolderPath + \"sdc_data_cleaned.pkl\")\n",
    "print('cleaned sdc_data has been saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### +++ Comment +++\n",
    "the given SDC data sample size is 10.026 after preparation.\n",
    "\n",
    "According to Lowry et al, 11.103 samples should be left after preparation.\n",
    "\n",
    "The achieved sample size is close to the target size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
